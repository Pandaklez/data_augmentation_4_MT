{"nbformat":4,"nbformat_minor":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","version":"3.7.7","file_extension":".py"},"notebookId":"3837013e-b3b6-47e8-8540-d0957ff60df4","kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"ydsNotebookPath":"Notebooks/rared_extended_data_model.ipynb"},"cells":[{"cell_type":"code","source":"#!g1.1\n%load_ext autoreload\n%autoreload 2\n\nfrom IPython.display import HTML, display\ndisplay(HTML(\"<style>.container { width:95% !important; }</style>\"))","metadata":{"cellId":"cxq3zud69vfl6wi2jlgwlq","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:95% !important; }</style>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"#!g1.1\n%pip install pymystem3\n%pip install pymorphy2\n%pip install razdel\n%pip install pympi-ling","metadata":{"cellId":"dg7aij6y2buzjua5vmo6m","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pymystem3 in /home/jupyter/.local/lib/python3.7/site-packages (0.2.0)\nRequirement already satisfied: requests in /kernel/lib/python3.7/site-packages (from pymystem3) (2.25.1)\nRequirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2021.5.30)\nRequirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.7/site-packages (from requests->pymystem3) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyter/.local/lib/python3.7/site-packages (from requests->pymystem3) (1.25.11)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\nRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\nRequirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\nRequirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: razdel in /home/jupyter/.local/lib/python3.7/site-packages (0.5.0)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pympi-ling in /home/jupyter/.local/lib/python3.7/site-packages (1.70.2)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":105},{"cell_type":"code","source":"#!g1.1\nimport re\nimport pymystem3\nimport os, sys\nsys.path.append('../')\nos.environ['KMP_DUPLICATE_LIB_OK']='True'\nfrom argparse import Namespace\n\nfrom pyeaf.pyeaf import EAFReader\nfrom pyeaf.text import VocabularyVectorizer, TextStemmer, RSLStemmer, GramBinarizer","metadata":{"cellId":"xz2yeutuwk9cdwlqjsvz4k","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#!g1.1\ner = EAFReader(directory=\"Разметки\")\ner.load()","metadata":{"cellId":"7yko210ertgjy50hwt9t8r","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<pyeaf.pyeaf.EAFReader at 0x7f22364ed410>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#!g1.1\nsentences_rus = er.get_sentences(er.RUS)\nsentences_rsl = er.get_sentences(er.RSL_R)\n\n# sentences_rsl_left = er.get_sentences(er.RSL_L)","metadata":{"cellId":"81b774bquywyhldm2h0et","trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#!g1.1\nsentences_rsl[:10]","metadata":{"cellId":"xqfcroj8ohdt1llh20i2bp","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"[['здравствуйте'],\n ['скоро', '23', 'февраль', 'праздник', 'мужчина2', 'poss:3ps'],\n ['8', 'м-а-р-т', 'праздник', 'poss:3ps', 'женщина'],\n ['мы', 'отдых'],\n ['день', 'другой:pl', 'работать2', 'обычно'],\n ['начать', '6', 'утро', 'до', '7', 'вечер2', 'время', 'Москва'],\n ['ждать2', 'poss:2ps:pl', '2ps:звонить:1ps'],\n ['до.свидания'],\n ['второй', 'шаг', 'ш-а-г'],\n [' здравствуйте']]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#!g1.1\nst = TextStemmer()\n\nstem_sentences_rus, gram_sentences_rus = st.stem(sentences_rus, gram=True)\nstem_sentences_rsl = list(map(RSLStemmer.stem_sentence, sentences_rsl))","metadata":{"cellId":"0ootae6aub9kj1i3m9l44n","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:848: UserWarning: The following variables cannot be serialized: st\n  warnings.warn(message)\n"}],"execution_count":6},{"cell_type":"code","source":"#!g1.1\nstem_sentences_rsl[:10]","metadata":{"cellId":"7pz9gyohuyfzhlocg5jro","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"[['здравствуйте'],\n ['скоро', '<nums>', 'февраль', 'праздник', 'мужчина2', 'poss', '3ps'],\n ['8', '<dact>', 'праздник', 'poss', '3ps', 'женщина'],\n ['мы', 'отдых'],\n ['день', 'другой', 'pl', 'работать2', 'обычно'],\n ['начать', '<nums>', 'утро', 'до', '<nums>', 'вечер2', 'время', 'москва'],\n ['ждать2', 'poss', '2ps', 'pl', '2ps', 'звонить', '1ps'],\n ['до.свидания'],\n ['второй', 'шаг', '<dact>'],\n ['здравствуйте']]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#!g1.1\nlen(stem_sentences_rsl)","metadata":{"cellId":"zad7o7n700jzxuj4m3nd1l","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"3269"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Extended data","metadata":{"cellId":"bmam1jsupvq9j4oeyjypj"}},{"cell_type":"code","source":"#!g1.1\n\n# readlines stem each line\nimport pandas as pd\n\nsentences_rus_fake = []\nsentences_rsl_fake = []\nfor _, d, files in os.walk('rared'):\n    print(files)\n    for file in files:\n        data = pd.read_csv('rared/' + file, sep='\\t', names=['rus', 'rsl'], encoding='utf-8')\n        sentences_rsl_fake.extend(data.rsl.tolist())\n        sentences_rus_fake.extend(data.rus.tolist())","metadata":{"cellId":"mtrmhba1lugicdjka5i2u","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"['rared_fake_sents_place_adverbs_fake_data.tsv', 'rared_fake_sents_time_adverbs_fake_data.tsv', 'rared_fake_sents_rsl_sv.tsv', 'rared_fake_sents_move_adverbs_fake_data.tsv', 'rared_fake_sents_rsl_svo_45.tsv', 'rared_fake_sents_rsl_svo_33.tsv', 'rared_fake_sents_rsl_svo_47.tsv', 'rared_fake_sents_rsl_svo_34.tsv', 'rared_fake_sents_rsl_svo_39.tsv', 'rared_fake_sents_rsl_svo_35.tsv', 'rared_fake_sents_rsl_svo_37.tsv', 'rared_fake_sents_rsl_svo_50.tsv', 'rared_fake_sents_rsl_svo_49.tsv', 'rared_fake_sents_rsl_svo_42.tsv', 'rared_fake_sents_rsl_svo_32.tsv', 'rared_fake_sents_rsl_svo_31.tsv', 'rared_fake_sents_rsl_svo_48.tsv', 'rared_fake_sents_rsl_svo_36.tsv', 'rared_fake_sents_rsl_svo_30.tsv', 'rared_fake_sents_rsl_svo_40.tsv', 'rared_fake_sents_rsl_svo_46.tsv', 'rared_fake_sents_rsl_svo_43.tsv', 'rared_fake_sents_rsl_svo_44.tsv', 'rared_fake_sents_rsl_svo_38.tsv', 'rared_fake_sents_rsl_svo_41.tsv']\n"}],"execution_count":9},{"cell_type":"code","source":"#!g1.1\nprint(len(sentences_rsl_fake))","metadata":{"cellId":"xkagu2kiffm9etzskle3re","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"950555\n"}],"execution_count":10},{"cell_type":"code","source":"#!g1.1\nsentences_rus_fake[:10]","metadata":{"cellId":"3nw8mz5a8qyh5pckx03lku","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"['Мой друг сразу же не купил пальто.',\n 'Рано бывает такое, что действительно начальник готов взять человека с инвалидностью, но он не знает какую работу ему предложить',\n 'Они набрали взрослых детей уже закончивших школы, у которых не было русского языка.',\n 'Пожалуйста, поторопись, чтобы очереди не было.',\n 'Были попытки глухих уезжать в села, создавать совхозы.',\n 'Или, например, человек хочет после вставать, чтобы все успевать, но не может, потому что друзья его затягивают и вынуждают сидеть допоздна; получается, что виноваты они, но это не так.',\n 'Я поняла, что иногда думала, что образование не особо важно, но нет, оно необходимо.',\n 'Я это сразу в шутку называл город вогоград ',\n 'Регулярно глухие карманные часы.',\n 'Навсегда другое время было']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Пробую отскорить классификатором предложения из 950 000 нагенерированных\n\nИ взять только хорошие, выше 0.8 для начала\n\nЗаодно я сохраняю скор для каждого предложения","metadata":{"cellId":"rlpq0v6p837vz9yiwyqg7"}},{"cell_type":"code","source":"#!g1.1\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom string import punctuation\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n%matplotlib inline","metadata":{"cellId":"9devbwqq9sx3t5ysx2gl","trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#!g1.1\nclass Clf(nn.Module):\n    \n    def __init__(self, vocab_size, embedding_dim, output_dim):\n        \n        super().__init__()          \n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.flatten = nn.Flatten() # вместо усреднения склеим все в 1 вектор\n        self.fc = nn.Linear(embedding_dim*MAX_LEN, output_dim) # размер склееного вектора - размер эмбединга на MAX_LEN\n        self.act = nn.Sigmoid() # активацию менять даже не пришлось, так как у нас бинарная классификация\n                                # если классов больше 2, то нужно поставить nn.Softmax()\n        \n    def forward(self, text):\n        \n        embedded = self.embedding(text)   \n        hidden = self.flatten(embedded)\n        dense_outputs=self.fc(hidden)\n        outputs=self.act(dense_outputs) \n        \n        return outputs","metadata":{"cellId":"nt233xy43kzlki1e392ep","trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#!g1.1\nMAX_LEN = 70\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# load again the model that we saved\nmodel_clf = Clf(14250, 30, 1)\nmodel_clf.load_state_dict(torch.load(\"clf_simple.pt\"))\nmodel_clf.eval()","metadata":{"cellId":"osm1i0ajkm9wdreu8ref4h","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Clf(\n  (embedding): Embedding(14250, 30)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc): Linear(in_features=2100, out_features=1, bias=True)\n  (act): Sigmoid()\n)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"#!g1.1\nfiltered_vocab = torch.load('filtered_vocab.pth')","metadata":{"cellId":"pbr3qtuzkgjvrfzitvpje","trusted":true},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#!g1.1\n# индексируем слова\nword2id = {'PAD':0}\n\nfor word in filtered_vocab:\n    word2id[word] = len(word2id)","metadata":{"cellId":"l4jc5zfum8qv5egkkamd","trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#!g1.1\ndef preprocess(text):\n    tokens = text.lower().split()\n    tokens = [token.strip(punctuation) for token in tokens]\n    tokens = [token for token in tokens if token]\n    return tokens\n\ndef prepare_texts_to_pred(text):\n    # в index будут индексы от 0 до len(rsl_svo_50.rus) = len(data)\n    # по ним мы достанем тексты, предобработаем, переведем в векторы, западим и вернем\n    tokens = preprocess(text) # токенизируем\n    ids = [word2id[token] for token in tokens if token in word2id][:MAX_LEN]\n    ids = torch.nn.functional.pad(torch.LongTensor(ids), \n                                  (0, MAX_LEN-len(ids)), \n                                  mode='constant',\n                                  value=0)\n    return ids\n\nmodel_clf.to(device)","metadata":{"cellId":"8uodhhniwqia41oelm4yln","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Clf(\n  (embedding): Embedding(14250, 30)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (fc): Linear(in_features=2100, out_features=1, bias=True)\n  (act): Sigmoid()\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"#!g1.1\nwith open('rared_good_fake_sents.tsv', 'w', encoding='utf-8') as f:\n    for i, rus in enumerate(tqdm(sentences_rus_fake)):  # 950 000\n        sent = prepare_texts_to_pred(rus)\n        # single_pred = model(sent.unsqueeze(0).to(device)).detach().to('cpu').numpy().tolist()[0][0]\n        single_pred = model(sent.unsqueeze(0)).detach().numpy().tolist()[0][0]\n        \n        # вообще лучший f1-score для класса хороших предожений был на 0.4\n        if single_pred > 0.5: \n            # print(rus, round(single_pred, 4))\n            f.write(rus + '\\t' + sentences_rsl_fake[i] + '\\t' + str(single_pred) + '\\n')","metadata":{"cellId":"m802iudjdjde2uk4i0fp9h","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 950555/950555 [01:34<00:00, 10042.21it/s]\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:848: UserWarning: The following variables cannot be serialized: f\n  warnings.warn(message)\n"}],"execution_count":29},{"cell_type":"code","source":"#!g1.1\nrared_good = pd.read_csv(\"rared_good_fake_sents.tsv\", sep=\"\\t\", names=['rus', 'rsl', 'pred'])\nrared_good.head()","metadata":{"cellId":"9b2pfgzmmzhmw4xd6vwfs","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                                 rus  \\\n0  Или, например, человек хочет после вставать, ч...   \n1  Например, скоро, на предприятии вог, на швейно...   \n2                               Да, мы после хотели.   \n3  Вообще, мы рано думали что нужно добавить жест...   \n4                                    Дочь достигает.   \n\n                                                 rsl      pred  \n0  есть тоже люди кто желание после вставать2 что...  0.515437  \n1  что скоро пример завод вог завод шить2 шить3 п...  0.517674  \n2                     indx желание после indx да :pl  0.519577  \n3  результат indx рано думать что необходимость ж...  0.517183  \n4                                     Дочь достигать  0.507185  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rus</th>\n      <th>rsl</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Или, например, человек хочет после вставать, ч...</td>\n      <td>есть тоже люди кто желание после вставать2 что...</td>\n      <td>0.515437</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Например, скоро, на предприятии вог, на швейно...</td>\n      <td>что скоро пример завод вог завод шить2 шить3 п...</td>\n      <td>0.517674</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Да, мы после хотели.</td>\n      <td>indx желание после indx да :pl</td>\n      <td>0.519577</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Вообще, мы рано думали что нужно добавить жест...</td>\n      <td>результат indx рано думать что необходимость ж...</td>\n      <td>0.517183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Дочь достигает.</td>\n      <td>Дочь достигать</td>\n      <td>0.507185</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"#!g1.1\nlen(rared_good)","metadata":{"cellId":"j3jl6ixvubhulskll4kl","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"19001"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"~ ~ ~ ~ ~","metadata":{"cellId":"m7rga5reaee0io55g6kzen"}},{"cell_type":"code","source":"#!g1.1\nfrom tqdm import tqdm\nimport numpy as np\n\nst = TextStemmer()\n\nlength = len(sentences_rsl_fake)\n\nstem_sentences_rsl_fake = []\nfor i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n    #print(stem_sentences_rsl_fake)\n    batch = list(map(RSLStemmer.stem_sentence, sentences_rsl_fake[i:i+100000]))\n    stem_sentences_rsl_fake.extend(batch)","metadata":{"cellId":"2wc1m0zrb17obk2lahogm8"},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 10/10 [00:32<00:00,  3.28s/it]\n"}],"execution_count":12},{"cell_type":"code","source":"#!g1.1\nlength = len(sentences_rus_fake)\n\nstem_sentences_rus_fake, gram_sentences_rus_fake = [], []\nfor i in tqdm(range(0, length, 100000)):  # instead of second position -> length\n    #print(stem_sentences_rsl_fake)\n    batch_stem, batch_gram = st.stem(sentences_rus_fake[i:i+100000], gram=True)\n    stem_sentences_rus_fake.extend(batch_stem)\n    gram_sentences_rus_fake.extend(batch_gram)","metadata":{"cellId":"uaka4vcn5kcbz7arsbzk45"},"outputs":[{"output_type":"stream","name":"stderr","text":"100%|██████████| 10/10 [03:01<00:00, 18.15s/it]\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:840: UserWarning: The following variables cannot be serialized: st\n  warnings.warn(message)\n"}],"execution_count":13},{"cell_type":"code","source":"#!g1.1\ngram_sentences_rus_fake[:2]","metadata":{"cellId":"4d7of2qjp9mhnp9fu43m2n"},"outputs":[{"output_type":"display_data","data":{"text/plain":"[[['им', 'неод', 'муж', 'APRO', 'вин', 'ед'],\n  ['им', 'муж', 'од', 'ед', 'S'],\n  ['ADV'],\n  ['PART'],\n  ['PART'],\n  ['сов', 'прош', 'муж', 'ед', 'пе', 'изъяв', 'V'],\n  ['им', 'неод', 'мн', 'дат', 'твор', 'пр', 'род', 'вин', 'сред', 'ед', 'S']],\n [['ADV'],\n  ['несов', 'непрош', 'нп', 'ед', 'изъяв', 'V', '3-л'],\n  ['им', 'APRO', 'вин', 'сред', 'ед'],\n  ['CONJ'],\n  ['вводн', 'ADV'],\n  ['им', 'муж', 'од', 'ед', 'S'],\n  ['A', 'кр', 'ед', 'муж'],\n  ['сов', 'V', 'пе', 'инф'],\n  ['муж', 'од', 'род', 'вин', 'ед', 'S'],\n  ['PR'],\n  ['неод', 'S', 'твор', 'ед', 'жен'],\n  ['CONJ'],\n  ['им', 'муж', 'SPRO', 'ед', '3-л'],\n  ['PART'],\n  ['несов', 'непрош', 'ед', 'пе', 'изъяв', 'V', '3-л'],\n  ['вин', 'ед', 'жен', 'APRO'],\n  ['неод', 'S', 'вин', 'ед', 'жен'],\n  ['муж', 'SPRO', 'дат', 'ед', '3-л'],\n  ['сов', 'V', 'пе', 'инф']]]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"#!g1.1\nstem_sentences_rus_fake[:4]","metadata":{"cellId":"iocxv3jlqg9zad3gxx2is"},"outputs":[{"output_type":"display_data","data":{"text/plain":"[['мой', 'друг', 'сразу', 'же', 'не', 'купить', 'пальто'],\n ['рано',\n  'бывать',\n  'такой',\n  'что',\n  'действительно',\n  'начальник',\n  'готовый',\n  'взять',\n  'человек',\n  'с',\n  'инвалидность',\n  'но',\n  'он',\n  'не',\n  'знать',\n  'какой',\n  'работа',\n  'он',\n  'предлагать'],\n ['они',\n  'набирать',\n  'взрослый',\n  'ребенок',\n  'уже',\n  'заканчивать',\n  'школа',\n  'у',\n  'который',\n  'не',\n  'быть',\n  'русский',\n  'язык'],\n ['пожалуйста', 'поторопиться', 'чтобы', 'очередь', 'не', 'быть']]"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"#!g1.1\nstem_sentences_rus[:4]","metadata":{"cellId":"hciyevookhb151hynj8bi8"},"outputs":[{"output_type":"display_data","data":{"text/plain":"[['здравствовать'],\n ['скоро', 'февраль', 'мужской', 'праздник'],\n ['март', 'женский', 'праздник'],\n ['мы', 'отдыхать']]"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Put all data in one bucket","metadata":{"cellId":"150wb172zwzmehxtmu5v7"}},{"cell_type":"code","source":"#!g1.1\nfrom sklearn.model_selection import train_test_split\n\ntrain_rus, test_rus, train_gram_rus, test_gram_rus, train_rsl, test_rsl = train_test_split(stem_sentences_rus + stem_sentences_rus_fake,\n                                                                                           gram_sentences_rus + gram_sentences_rus_fake,\n                                                                                           stem_sentences_rsl + stem_sentences_rsl_fake,\n                                                                                           test_size=0.2)","metadata":{"cellId":"lpvkwon3sdo4qgchhk7xxu"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#!g1.1\nvoc_rus = VocabularyVectorizer(phrase_border=True)\nbin_gram = GramBinarizer(phrase_border=True)\nvoc_rsl = VocabularyVectorizer(phrase_border=True)","metadata":{"cellId":"8bcdwp9svciwvdfrxjldc"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#!g1.1\nvoc_rus = voc_rus.fit(train_rus)\nbin_gram = bin_gram.fit(train_gram_rus)\nvoc_rsl = voc_rsl.fit(train_rsl)","metadata":{"cellId":"fakj0x4ua42o3gsrzyqwl"},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#!g1.1\n#vec_sentences_rus_train = voc_rus.text_to_index(train_rus)\n#vec_gram_train = bin_gram.transform(train_gram_rus)\n#vec_sentences_rsl_train = voc_rsl.text_to_index(train_rsl)","metadata":{"cellId":"zsmb1qnsvxg40unnlpii6d"},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: State committing stage cannot be interrupted. Please wait.\n  warnings.warn(self._warn_message)\n"}],"execution_count":20},{"cell_type":"markdown","source":"## Net","metadata":{"cellId":"xnz9iqhiwf1qaxpm7wgat"}},{"cell_type":"code","source":"#!g1.1\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import functional as F\n\nfrom model.model import Translator","metadata":{"cellId":"ch8i8ft2845mv635g99hn"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#!g1.1\ndef set_seed_everywhere(seed, cuda):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if cuda:\n        torch.cuda.manual_seed_all(seed)\n\ndef handle_dirs(dirpath):\n    if not os.path.exists(dirpath):\n        os.makedirs(dirpath)\n\ndef make_train_state(args):\n    return {'stop_early': False,\n            'early_stopping_step': 0,\n            'early_stopping_best_val': 1e8,\n            'learning_rate': args.learning_rate,\n            'epoch_index': 0,\n            'train_loss': [],\n            'train_acc': [],\n            'val_loss': [],\n            'val_acc': [],\n            'test_loss': -1,\n            'test_acc': -1,\n            'model_filename': args.model_state_file}\n\ndef update_train_state(args, model, train_state):\n    \"\"\"Handle the training state updates.\n    Components:\n     - Early Stopping: Prevent overfitting.\n     - Model Checkpoint: Model is saved if the model is better\n    \n    :param args: main arguments\n    :param model: model to train\n    :param train_state: a dictionary representing the training state values\n    :returns:\n        a new train_state\n    \"\"\"\n\n    # Save one model at least\n    if train_state['epoch_index'] == 0:\n        torch.save(model.state_dict(), train_state['model_filename'])\n        train_state['stop_early'] = False\n\n    # Save model if performance improved\n    elif train_state['epoch_index'] >= 1:\n        loss_tm1, loss_t = train_state['val_loss'][-2:]\n         \n        # If loss worsened\n        if loss_t >= loss_tm1:\n            # Update step\n            train_state['early_stopping_step'] += 1\n        # Loss decreased\n        else:\n            # Save the best model\n            if loss_t < train_state['early_stopping_best_val']:\n                torch.save(model.state_dict(), train_state['model_filename'])\n                train_state['early_stopping_best_val'] = loss_t\n\n            # Reset early stopping step\n            train_state['early_stopping_step'] = 0\n\n        # Stop early ?\n        train_state['stop_early'] = \\\n            train_state['early_stopping_step'] >= args.early_stopping_criteria\n\n    return train_state\n\ndef normalize_sizes(y_pred, y_true):\n    \"\"\"Normalize tensor sizes\n    \n    Args:\n        y_pred (torch.Tensor): the output of the model\n            If a 3-dimensional tensor, reshapes to a matrix\n        y_true (torch.Tensor): the target predictions\n            If a matrix, reshapes to be a vector\n    \"\"\"\n    if len(y_pred.size()) == 3:\n        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n    if len(y_true.size()) == 2:\n        y_true = y_true.contiguous().view(-1)\n    return y_pred, y_true\n\ndef compute_accuracy(y_pred, y_true, mask_index):\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\n\n    _, y_pred_indices = y_pred.max(dim=1)\n    \n    correct_indices = torch.eq(y_pred_indices, y_true).float()\n    valid_indices = torch.ne(y_true, mask_index).float()\n    \n    n_correct = (correct_indices * valid_indices).sum().item()\n    n_valid = valid_indices.sum().item()\n\n    return n_correct / n_valid * 100\n\ndef sequence_loss(y_pred, y_true, mask_index):\n    y_pred, y_true = normalize_sizes(y_pred, y_true)\n    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)","metadata":{"cellId":"loesuglyajds1prgnsqos"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#!g1.1\nimport random \n\ndef batch_generator(rus_data, rsl_data, batch_size=32):\n    rus_data = np.array(rus_data)\n    rsl_data = np.array(rsl_data)\n    \n    data_length = len(rus_data)\n    tail_length = batch_size - data_length % batch_size\n    index = list(range(data_length))\n    random.shuffle(index)\n    \n    index = np.array(index + random.choices(index, k=tail_length))\n    num_batches = len(index) // batch_size\n    index = index.reshape((num_batches, batch_size))\n    \n    for batch_ind, inds in enumerate(tqdm(index)):\n        yield batch_ind, torch.tensor(rus_data[inds]), torch.tensor(rsl_data[inds])","metadata":{"cellId":"jwej4714bbpkp6iom68ha"},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Load model \\ train model","metadata":{"cellId":"vc6fma3rwmdzmz3h5tau4"}},{"cell_type":"code","source":"#!g1.1\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"cellId":"goluuqm19cc4no9zl7rj86"},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#!g1.1\n\n# Model class must be defined somewhere\nmodel = torch.load('rared_data_model.pth', map_location=device)\nmodel.eval()","metadata":{"cellId":"gwsefekc9aj0pdfshzto"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Translator(\n  (encoder): TranslatorEncoder(\n    (rus_embeddings): Embedding(5670, 16, max_norm=1.0)\n    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n  )\n  (decoder): TranslatorDecoder(\n    (rsl_embedding): Embedding(5103, 16, max_norm=1.0)\n    (gru_cell): GRUCell(144, 128)\n    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n    (classifier): Linear(in_features=256, out_features=5103, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## Evaluate","metadata":{"cellId":"fz6poqoqwipit2xog16nd"}},{"cell_type":"code","source":"#!g1.1\n\n#vec_gram_test = bin_gram.transform(test_gram_rus)\nvec_sentences_rsl_test = voc_rsl.text_to_index(test_rsl)\nvec_sentences_rus_test = voc_rus.text_to_index(test_rus)","metadata":{"cellId":"70hdwgzbd082qkm0mvqgkx"},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#!g1.1\nlen(vec_sentences_rus_test)","metadata":{"cellId":"iqkonlpyigo4buxkcpjmg"},"outputs":[{"output_type":"display_data","data":{"text/plain":"190765"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"#!g1.1\nregex = re.compile(r'(?:<bos>|<eos>.*)')\ndef pred_vs_rsl(tensor, true_rsl): #, rus):\n    \n    tensor = tensor.argmax(2).tolist()\n    \n    pred_rsl = voc_rsl.index_to_text(tensor)\n    true_rsl = voc_rsl.index_to_text(true_rsl)\n    #rus = voc_rus.index_to_text(rus)\n                   \n    f = lambda x: regex.sub('', \" \".join(x))\n                   \n    pred_rsl = (f(sentence) for sentence in pred_rsl)\n    true_rsl = (f(sentence) for sentence in true_rsl)\n    #true_rus = (f(sentence) for sentence in rus)\n    \n    return pred_rsl, true_rsl #, true_rus","metadata":{"cellId":"7hbymlr1mlx5ppiwqju6qs"},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#!g1.1\n# del names of variables that I do not need anymore\ndel sentences_rus\ndel sentences_rsl\ndel stem_sentences_rus\ndel gram_sentences_rus\ndel stem_sentences_rsl\ndel train_rus\ndel train_rsl\ndel train_gram_rus\ndel bin_gram","metadata":{"cellId":"6dlf94grtq269ivuwe13z"},"outputs":[],"execution_count":27},{"cell_type":"code","source":"#!g1.1\nlength = len(vec_sentences_rus_test) - 1000  # 190 765\n\ntrans, truth_rsl = [], []\nfor i in tqdm(range(0, length, 1000)):\n    rus_test_batch = vec_sentences_rus_test[i:i+1000]\n    rsl_test_batch = vec_sentences_rsl_test[i:i+1000]\n    t_sentences_rus_test_batch = torch.tensor(rus_test_batch).to(device)\n    t_sentences_rsl_test_batch = torch.tensor(rsl_test_batch).to(device)\n    \n    y_pred_batch = []\n    for j in range(0, 1000, 100):\n        y_pred_batch.append(model(t_sentences_rus_test_batch[j:j+100], t_sentences_rsl_test_batch[j:j+100], 0).to(device))\n    y_pred_batch = torch.cat(y_pred_batch, dim=1)\n    \n    trans_batch, truth_rsl_batch = pred_vs_rsl(y_pred_batch, t_sentences_rsl_test_batch)  #, t_sentences_rus_test_batch)\n    for el_trans, el_truth in zip(trans_batch, truth_rsl_batch):\n        truth_rsl.append(el_truth)\n        trans.append(el_trans)","metadata":{"cellId":"qgfbukaiefkl8clyzn4vrf"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"\"embedding_renorm_cuda_\" not implemented for 'Float'","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)","\u001B[0;32m<ipython-input-44-c1028156df70>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0my_pred_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1000\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0my_pred_batch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrus_test_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrsl_test_batch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m     \u001B[0my_pred_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/work/resources/model/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, rus_sentances, rsl_sentence, sample_probability)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrus_sentances\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrsl_sentence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_probability\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         \u001B[0mencoder_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfinal_hidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrus_sentances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    159\u001B[0m         \u001B[0mdecoded_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mencoder_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfinal_hidden_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrsl_sentence\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_probability\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/work/resources/model/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, rus_sentances)\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrus_sentances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrus_birnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten_parameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0mrus_embedded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrus_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrus_sentances\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;31m# rus_rnn_h.shape = (rnn_size, batch_size, rus_emb_size)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    158\u001B[0m         return F.embedding(\n\u001B[1;32m    159\u001B[0m             \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001B[0m\u001B[1;32m    161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2040\u001B[0m         \u001B[0;31m#   torch.embedding_renorm_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2041\u001B[0m         \u001B[0;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2042\u001B[0;31m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2043\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2044\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36m_no_grad_embedding_renorm_\u001B[0;34m(weight, input, max_norm, norm_type)\u001B[0m\n\u001B[1;32m   1944\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1945\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1946\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1948\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mRuntimeError\u001B[0m: \"embedding_renorm_cuda_\" not implemented for 'Float'"]},{"output_type":"stream","name":"stderr","text":" 99%|█████████▉| 190/191 [16:48<00:05,  5.31s/it]\n/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:840: UserWarning: The following variables cannot be serialized: trans_batch, truth_rsl_batch\n  warnings.warn(message)\n"}],"execution_count":44},{"cell_type":"code","source":"#!g1.1\ntruth_rsl[0]","metadata":{"cellId":"wscqleq45s9em4ohbi5zyu"},"outputs":[{"output_type":"display_data","data":{"text/plain":"' напольная плитка отложенный чулан '"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"#!g1.1\n#trans, truth_rsl, rus = pred_vs_rsl(y_pred, torch.tensor(vec_sentences_rsl_test), torch.tensor(vec_sentences_rus_test))","metadata":{"cellId":"ulkub0msk182cty427k8i4"},"outputs":[],"execution_count":103},{"cell_type":"code","source":"#!g1.1\nfor i in range(10):\n    print(\"RSL: \", truth_rsl[i])\n    print(\"TRANS: \", trans[i])\n    #print(\"RUS: \", rus[i])\n    print('\\n')","metadata":{"cellId":"uyqj7mf0zuj0hb8buvrhb"},"outputs":[{"output_type":"stream","name":"stdout","text":"RSL:   напольная плитка отложенный чулан \nTRANS:   слышащий плитка отложенный чулан \n\n\nRSL:   хомяк преувеличивать стул \nTRANS:   хомяк прилипание стул \n\n\nRSL:   христос жать респиратор \nTRANS:   правша проныра респиратор \n\n\nRSL:   придурок подавленный карабин \nTRANS:   окончание подавленный комета \n\n\nRSL:   попугай подожди жабры \nTRANS:   обезьяна подожди жабры \n\n\nRSL:   обезьяна выдуманный борода \nTRANS:   обезьяна знакомить борода \n\n\nRSL:   червяк модифицировать весна \nTRANS:   червяк модифицировать весна \n\n\nRSL:   христос запугивать арфа \nTRANS:   христос запугивать арфа \n\n\nRSL:   сосед копать алчность \nTRANS:   сосед учить алчность \n\n\nRSL:   потому что восхищать талия \nTRANS:   обещание что восхищать талия \n\n\n"}],"execution_count":41},{"cell_type":"code","source":"#!g1.1\nlen(trans)","metadata":{"cellId":"h5emo8ghj7988ojtwgbz6d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"19000"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"cellId":"3q0vn1lp7qobvtsi901py"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nimport sacrebleu\n\nrus_rsl_bleu = sacrebleu.corpus_bleu(trans, [truth_rsl])\nprint(\"--------------------------\")\nprint(\"Russian to RSL: \", rus_rsl_bleu.score)","metadata":{"cellId":"bcug48wn03iadm51g5xxi"},"outputs":[{"output_type":"stream","name":"stdout","text":"--------------------------\nRussian to RSL:  37.75458936063675\n"}],"execution_count":43}]}