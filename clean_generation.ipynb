{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "234f612a",
   "metadata": {
    "cellId": "hqfxt7e42t96jjhizwxan"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os, sys\n",
    "import re, random\n",
    "import copy\n",
    "import json\n",
    "import pympi\n",
    "import pymystem3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyeaf.pyeaf import EAFReader\n",
    "from pyeaf.text import VocabularyVectorizer, TextStemmer, RSLStemmer, GramBinarizer\n",
    "from model.model import device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c17f2",
   "metadata": {
    "cellId": "87vcvij4cv5abw537d486o"
   },
   "source": [
    "* существительные в именительном падеже\n",
    "* существительные в винительном падеже\n",
    "* переходные глаголы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31394bbe",
   "metadata": {
    "cellId": "y4nsbzzy5nmbetgjcumfnm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyeaf.pyeaf.EAFReader at 0x7f5f581663d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "er = EAFReader(directory=\"../Разметки eaf\")\n",
    "er.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53497d2",
   "metadata": {
    "cellId": "1colu3btkgwksoa458tidm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentences_rus = er.get_sentences(er.RUS)\n",
    "sentences_rsl = er.get_sentences(er.RSL_R)\n",
    "\n",
    "# sentences_rsl_left = er.get_sentences(er.RSL_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c80ef2b",
   "metadata": {
    "cellId": "2bykqbtabssbnlgkl45pch"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "st = TextStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03afb41",
   "metadata": {
    "cellId": "c86nknll8fxw25egusj6c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "stem_sentences_rus, gram_sentences_rus = st.stem(sentences_rus, gram=True)\n",
    "stem_sentences_rsl = list(map(RSLStemmer.stem_sentence, sentences_rsl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d814a",
   "metadata": {
    "cellId": "ygt7lcexsefhl6mlse6vw"
   },
   "source": [
    "Prep for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900b2679",
   "metadata": {
    "cellId": "d78604sqnpu0f9qkm6rtkvq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "with open(\"animate.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    anim_nouns = [line.strip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18197c8a",
   "metadata": {
    "cellId": "3f3wrnenesn0r0b971e705"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "with open(\"inanimate.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inanim_nouns = [line.strip('\\n') for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc28c419",
   "metadata": {
    "cellId": "gwkc8xuj256xaa62c34gg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def split_by_gender(nouns):\n",
    "    nouns_m, nouns_f, nouns_n = [], [], []\n",
    "    for noun in nouns:\n",
    "        if 'муж' in st.stem(noun)[1][0][0]:\n",
    "            nouns_m.append(noun)\n",
    "        elif 'жен' in st.stem(noun)[1][0][0]:\n",
    "            nouns_f.append(noun)\n",
    "        elif 'сред' in st.stem(noun)[1][0][0]:\n",
    "            nouns_n.append(noun)\n",
    "    return nouns_m, nouns_f, nouns_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98fd5d03",
   "metadata": {
    "cellId": "sghy4aevc9buh3zckfng99"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inan_m_nouns, inan_f_nouns, inan_n_nouns = split_by_gender(inanim_nouns)\n",
    "anim_m_nouns, anim_f_nouns, anim_n_nouns = split_by_gender(anim_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1d3e29",
   "metadata": {
    "cellId": "8ksthbkoiwlgu1qm5101r"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from string import punctuation\n",
    "\n",
    "noun_np_gen = []\n",
    "for line in open(\"patterns.noun_np_gen.txt\", \"r\", encoding=\"utf-8\"):\n",
    "    if not (set(line) & set(punctuation)):\n",
    "        noun_np_gen.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d9da497",
   "metadata": {
    "cellId": "d41o310k23wqdjtllg855"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# разделить на одуш\\неодуш\n",
    "anim_noun_np_gen = []\n",
    "inanim_noun_np_gen = []\n",
    "for np in noun_np_gen:\n",
    "    main_word = np.split()[0]\n",
    "    if 'неод' in st.stem(main_word)[1][0][0]:\n",
    "        inanim_noun_np_gen.append(np)\n",
    "    else:\n",
    "        anim_noun_np_gen.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af86cab5",
   "metadata": {
    "cellId": "e34t7jdnou5yugumvp2u8n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inanim_m_noun_np_gen, inanim_f_noun_np_gen, inanim_n_noun_np_gen = [], [], []\n",
    "for np in inanim_noun_np_gen:\n",
    "    noun = np.split()[0]\n",
    "    if 'муж' in st.stem(noun)[1][0][0]:\n",
    "        inanim_m_noun_np_gen.append(np)\n",
    "    elif 'жен' in st.stem(noun)[1][0][0]:\n",
    "        inanim_f_noun_np_gen.append(np)\n",
    "    elif 'сред' in st.stem(noun)[1][0][0]:\n",
    "        inanim_n_noun_np_gen.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f6a584",
   "metadata": {
    "cellId": "9qm687k7vorrezyxv10lfi"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "anim_m_noun_np_gen, anim_f_noun_np_gen, anim_n_noun_np_gen = [], [], []\n",
    "for np in anim_noun_np_gen:\n",
    "    noun = np.split()[0]\n",
    "    if 'муж' in st.stem(noun)[1][0][0]:\n",
    "        anim_m_noun_np_gen.append(np)\n",
    "    elif 'жен' in st.stem(noun)[1][0][0]:\n",
    "        anim_f_noun_np_gen.append(np)\n",
    "    elif 'сред' in st.stem(noun)[1][0][0]:\n",
    "        anim_n_noun_np_gen.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d07794",
   "metadata": {
    "cellId": "2erg10he7wv0fbbj09l7lw"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "words = pd.read_csv(\"animation_pos.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bd15750",
   "metadata": {
    "cellId": "6pty6w90q38m8bh3kw6i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tr_verbs, intr_verbs = [], []\n",
    "for verb in words[words['pos'] == 'V'].itertuples():\n",
    "    analysis = json.loads(verb.analysis.replace('\\'', '\\\"'))\n",
    "    gr = analysis[0]['analysis'][0]['gr']\n",
    "    if 'пе' in gr:\n",
    "        tr_verbs.append(verb.text)\n",
    "    elif 'нп' in gr:\n",
    "        intr_verbs.append(verb.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69046c6",
   "metadata": {
    "cellId": "2bw76581mescedpsrda9nu"
   },
   "source": [
    "## Generation itself\n",
    "\n",
    "should turn it into class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915126ad",
   "metadata": {
    "cellId": "v66tnh71mmoryenkr82qal"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "depth = lambda L: isinstance(L, list) and max(map(depth, L))+1\n",
    "\n",
    "def flatten(S):\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])\n",
    "\n",
    "def drop_inner_nest(S):\n",
    "    for sublist in S:\n",
    "        if isinstance(sublist[0], list):\n",
    "            yield sublist[0]\n",
    "        else:\n",
    "            yield sublist\n",
    "\n",
    "def create_gr_n_tags(gr, old_gram_sent_rus):\n",
    "    # keep original case and number\n",
    "    tags = ['им', 'вин', 'род', 'дат', 'твор', 'пр', 'парт', 'местн', 'зват', 'ед', 'мн']\n",
    "    initial_tags = [el for el in old_gram_sent_rus if el in tags]\n",
    "    for i, word_gr in enumerate(gr):\n",
    "        gr[i] = [el for el in word_gr if el not in tags]\n",
    "        gr[i].extend(initial_tags)\n",
    "    return gr\n",
    "\n",
    "def create_rsl_gloss(old_rus_lemma, new_rus_lemma, old_stem_sent_rus: list, old_stem_rsl: list):\n",
    "    \"\"\"creates rsl glosses for the whole stemmed rsl sentence\"\"\"\n",
    "    # update stemmed rsl sentence\n",
    "    # return full rsl sentence as a list, not just updated words\n",
    "    # this does not work well because of things like посмотреть\\смотреть\n",
    "    new_stem_rsl = copy.deepcopy(old_stem_rsl)\n",
    "    #print('create_rsl_gloss')\n",
    "    #print('new_rus_lemma', new_rus_lemma)\n",
    "    found = False\n",
    "    for i, gloss in enumerate(old_stem_rsl):\n",
    "        if gloss == old_rus_lemma:\n",
    "            #print('rus lemma based change')\n",
    "            new_stem_rsl[i] = new_rus_lemma\n",
    "            found = True\n",
    "    if not found:\n",
    "        # so we have to use index replacement as well\n",
    "        for j, gloss in enumerate(old_stem_sent_rus):\n",
    "            if gloss == old_rus_lemma and j < len(new_stem_rsl):\n",
    "                #print('index based change')\n",
    "                new_stem_rsl[j] = new_rus_lemma\n",
    "    #print(\"new_stem_rsl on this step\")\n",
    "    #pprint(new_stem_rsl)\n",
    "    return new_stem_rsl\n",
    "\n",
    "def make_replacments(replacement, old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus: list, old_stem_rsl: list, keep_gr=2):\n",
    "    old_rus_lemma = old_stem_sent_rus_one\n",
    "    old_stem_sent_rus_one, gr = st.stem(replacement)\n",
    "    new_rus_lemma = old_stem_sent_rus_one[0]\n",
    "    if keep_gr==1:\n",
    "        old_gram_sent_rus_one = create_gr_n_tags(gr, old_gram_sent_rus_one)\n",
    "    elif keep_gr==0:\n",
    "        old_gram_sent_rus_one = gr\n",
    "    new_stem_rsl_one = create_rsl_gloss(old_rus_lemma, new_rus_lemma, old_stem_sent_rus, old_stem_rsl)\n",
    "    return old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl_one\n",
    "\n",
    "def pick_and_replace(old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus, old_stem_rsl, choices, complex_choices=None):\n",
    "    if complex_choices:\n",
    "        # decide between single noun of np with gen\n",
    "        pick = random.randint(0,1)  # 0 is single noun, 1 is np with gen\n",
    "        if not bool(pick):\n",
    "            choice = random.choice(choices)\n",
    "            if len(choice.split()) > 1:\n",
    "                old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl = make_replacments(choice, old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus, old_stem_rsl, keep_gr=1)\n",
    "                # this line is in the wrong place\n",
    "            else:\n",
    "                old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl = make_replacments(choice, old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus, old_stem_rsl, keep_gr=2)\n",
    "        else:\n",
    "            choice = random.choice(complex_choices)\n",
    "            old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl = make_replacments(choice, old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus, old_stem_rsl, keep_gr=0)\n",
    "    else: \n",
    "        choice = random.choice(choices)\n",
    "        old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl = make_replacments(choice, old_stem_sent_rus_one, old_gram_sent_rus_one, old_stem_sent_rus, old_stem_rsl, keep_gr=0)\n",
    "    return old_stem_sent_rus_one, old_gram_sent_rus_one, new_stem_rsl\n",
    "\n",
    "def generate_parallel_sentence(old_gram_sent_rus_init, old_stem_sent_rus_init, old_stem_rsl_init):\n",
    "    \"\"\"this function generates one parallel sentence\"\"\"\n",
    "    old_gram_sent_rus = copy.deepcopy(old_gram_sent_rus_init)\n",
    "    old_stem_sent_rus = copy.deepcopy(old_stem_sent_rus_init)\n",
    "    old_stem_rsl = copy.deepcopy(old_stem_rsl_init)\n",
    "    number_replacements = 0   \n",
    "    for k, gram in enumerate(old_gram_sent_rus_init):\n",
    "        # gender is relevant for nouns because of concord \n",
    "        if 'S' and 'од' and 'муж' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, anim_m_nouns, complex_choices=anim_m_noun_np_gen)\n",
    "        elif 'S' and 'неод'  and 'муж' in gram:\n",
    "            number_replacements += 1 \n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, inan_m_nouns, complex_choices=inanim_m_noun_np_gen)\n",
    "        elif 'S' and 'од' and 'жен' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, anim_f_nouns, complex_choices=anim_f_noun_np_gen)\n",
    "        elif 'S' and 'неод'  and 'жен' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, inan_f_nouns, complex_choices=inanim_f_noun_np_gen)\n",
    "        elif 'S' and 'од' and 'сред' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, anim_n_nouns, complex_choices=anim_n_noun_np_gen)\n",
    "        elif 'S' and 'неод'  and 'сред' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, inan_n_nouns, complex_choices=inanim_n_noun_np_gen)\n",
    "        elif 'V' and 'пе' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, tr_verbs)\n",
    "        elif 'V' and 'нп' in gram:\n",
    "            number_replacements += 1\n",
    "            old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_rsl = pick_and_replace(old_stem_sent_rus[k], old_gram_sent_rus[k], old_stem_sent_rus, old_stem_rsl, intr_verbs)\n",
    "\n",
    "        # если делать больше 5 замен, получается полный бред\n",
    "        # надо еще сделать замены не подряд, а типа рандомно пропускать шаги??\n",
    "        # может после переходного глагола всегда пропускать,\n",
    "        # потому что очень сложно случайным образом подобрать правильный прямой объект или и того хуже инфинитивный оборот\n",
    "        if number_replacements == 5:\n",
    "            break\n",
    "            \n",
    "    if number_replacements == 0:\n",
    "        # havent found anything to replace\n",
    "        return None, None, None\n",
    "    \n",
    "    # randomly pick word\n",
    "    # insert constituent in old_stem_sent_rus (stem\\gram before insertion)\n",
    "    # insert gram of constituent in old_gram_sent_rus it should inherent everything from the original word\n",
    "    # but if the length of replacement > 1, \n",
    "    # insert stemmed constituent in old_stem_rsl\n",
    "    # flatten lists of depth 3\n",
    "    if depth(old_gram_sent_rus) > 2:\n",
    "        old_gram_sent_rus = list(drop_inner_nest(list(drop_inner_nest(old_gram_sent_rus))))\n",
    "\n",
    "    return old_gram_sent_rus, list(flatten(old_stem_sent_rus)), list(flatten(old_stem_rsl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2482edd",
   "metadata": {
    "cellId": "p9lry8az1ad4ia6ucxdt6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stem_sents_rus, test_stem_rus, gram_sents_rus, test_gram_rus, stem_sents_rsl, test_rsl = train_test_split(stem_sentences_rus,\n",
    "                                                                                                          gram_sentences_rus,\n",
    "                                                                                                          stem_sentences_rsl,\n",
    "                                                                                                          test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78417c70",
   "metadata": {
    "cellId": "chhltlhwq888hy0265p4k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4876/4876 [00:36<00:00, 132.04it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_gram_sents_rus, new_stem_sents_rus, new_stem_rsls = [], [], []\n",
    "\n",
    "for n, gram in enumerate(tqdm(gram_sents_rus)):\n",
    "    k = random.randint(10, 30)\n",
    "    for i in range(k): \n",
    "        #generate one parallel sentence\n",
    "        \n",
    "        if stem_sents_rsl[n] is None or stem_sents_rsl[n] == []:\n",
    "            break\n",
    "            \n",
    "        #print(\"INITIAL GRAM\", gram_sents_rus[n])\n",
    "        #print(\"INITIAL RUS\", stem_sents_rus[n])\n",
    "        #print(\"INITIAL RSL\", stem_sents_rsl[n])\n",
    "        new_gram_sent_rus, new_stem_sent_rus, new_stem_rsl = generate_parallel_sentence(gram_sents_rus[n],\n",
    "                                                                                        stem_sents_rus[n],\n",
    "                                                                                        stem_sents_rsl[n])\n",
    "        \n",
    "        new_gram_sents_rus.append(new_gram_sent_rus)\n",
    "        new_stem_sents_rus.append(new_stem_sent_rus)\n",
    "        new_stem_rsls.append(new_stem_rsl)\n",
    "        #print(\"NEW GRAM \", new_gram_sent_rus)\n",
    "        #print(\"NEW RUS \", new_stem_sent_rus)\n",
    "        #print(\"NEW RSL \", new_stem_rsl)\n",
    "        #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55c580",
   "metadata": {
    "cellId": "1qevgomvu55ejkiwgkagmr"
   },
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba22fef",
   "metadata": {
    "cellId": "flnglhhvyawr4b7c0c1vrm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# save to some tsv file\n",
    "generated_dict = {'new_stem_sent_rus': new_stem_sents_rus, 'new_gram_sent_rus': new_gram_sents_rus, 'new_stem_rsl': new_stem_rsls}\n",
    "generated_data = pd.DataFrame.from_dict(generated_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32c9840",
   "metadata": {
    "cellId": "ichn7eoen7i2qt1xywfe"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "generated_data = generated_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b538ec6",
   "metadata": {
    "cellId": "9acrx71dgh91bp7ijwdjep"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "generated_data.to_csv('generated_stemed.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b744f30",
   "metadata": {
    "cellId": "v87z8j8c0bbeau2tt1sgpn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data = pd.DataFrame.from_dict({\"test_stem_rus\": test_stem_rus, \"test_gram_rus\": test_gram_rus, \"test_rsl\": test_rsl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f11d3a78",
   "metadata": {
    "cellId": "1qxaa3x0bgrwqubxmkuxv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ad9b41",
   "metadata": {
    "cellId": "vxg6wn38bpkn7atrfjpxj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data.to_csv('test_data.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f48b98",
   "metadata": {
    "cellId": "xryhmaeondes3qqrooj9"
   },
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ff2aaf",
   "metadata": {
    "cellId": "p2zsc0w1giby1wmr4xcx4o"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "generated_data = pd.read_csv('generated_stemed.csv', encoding='utf-8')\n",
    "\n",
    "generated_data['new_stem_sent_rus'] = generated_data['new_stem_sent_rus'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "generated_data['new_stem_rsl'] = generated_data['new_stem_rsl'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "generated_data['new_gram_sent_rus'] = generated_data['new_gram_sent_rus'].apply(lambda sent: json.loads(sent.replace('\\'', '\\\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128fe8fe",
   "metadata": {
    "cellId": "btn0w4izo7kgb4aw89rk6f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_data = pd.read_csv('test_data.csv', encoding='utf-8')\n",
    "\n",
    "test_data['test_stem_rus'] = test_data['test_stem_rus'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_rsl'] = test_data['test_rsl'].apply(lambda sent: sent.strip('[]\\'').split('\\', \\''))\n",
    "test_data['test_gram_rus'] = test_data['test_gram_rus'].apply(lambda sent: json.loads(sent.replace('\\'', '\\\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8589e641",
   "metadata": {
    "cellId": "7sz26ib73cktnnsnbnzh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220 56740\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(len(test_data), len(generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2b2537",
   "metadata": {
    "cellId": "0l3t6024ntoq0uubi910f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.150158618258724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "len(test_data)/len(generated_data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace9281",
   "metadata": {
    "cellId": "o8a72p65tk29ml3b1frxw"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78fd9e06",
   "metadata": {
    "cellId": "cwayrz8bxsu1mm0frs78r7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = VocabularyVectorizer(phrase_border=True)\n",
    "bin_gram = GramBinarizer(phrase_border=True)\n",
    "voc_rsl = VocabularyVectorizer(phrase_border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09c1941",
   "metadata": {
    "cellId": "ehsm9wp3tcv43rx7dkdwz2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "voc_rus = voc_rus.fit(list(generated_data['new_stem_sent_rus']))\n",
    "bin_gram = bin_gram.fit(list(generated_data['new_gram_sent_rus']))\n",
    "voc_rsl = voc_rsl.fit(list(generated_data['new_stem_rsl']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd505dab",
   "metadata": {
    "cellId": "yfib09m9a8ak0tksvnsllh"
   },
   "source": [
    "Save vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3684c59",
   "metadata": {
    "cellId": "xfvr7b2cznsgl08uo3hqst"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Save\\load vocabs\n",
    "import pickle\n",
    "\n",
    "def save_vocab(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()\n",
    "    \n",
    "def load_vocab(path):\n",
    "    output = open(path, 'rb')\n",
    "    vocab = pickle.load(output)\n",
    "    output.close()\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b046db4",
   "metadata": {
    "cellId": "6yd064vg2q7dczoz72nwm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "save_vocab(voc_rus, 'voc_rus.pkl')\n",
    "save_vocab(bin_gram, 'bin_gram.pkl')\n",
    "save_vocab(voc_rsl, 'voc_rsl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aeee39",
   "metadata": {
    "cellId": "yx2t6yypwklptrtb324n"
   },
   "source": [
    "Load vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b628cb7",
   "metadata": {
    "cellId": "ryy2t4xc2bl8epk710ph"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Load vocabs\n",
    "voc_rus = load_vocab('voc_rus.pkl')\n",
    "bin_gram = load_vocab('bin_gram.pkl')\n",
    "voc_rsl = load_vocab('voc_rsl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed3e1b2",
   "metadata": {
    "cellId": "wpdsb3t6h4i24ghsjpcv5n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['лягушка']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "voc_rus.index_to_text([[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b328c9c6",
   "metadata": {
    "cellId": "u4s3iia76209oo54v2pmx9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_sentences_rus_train = voc_rus.text_to_index(list(generated_data['new_stem_sent_rus']))\n",
    "vec_gram_train = bin_gram.transform(list(generated_data['new_gram_sent_rus']))\n",
    "vec_sentences_rsl_train = voc_rsl.text_to_index(list(generated_data['new_stem_rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d4006f",
   "metadata": {
    "cellId": "9s3crianrztrzwks95s21h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "words = [w for s in list(generated_data['new_stem_rsl']) for w in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824667b",
   "metadata": {
    "cellId": "1n73ldm0536pfy1y0jd3oa"
   },
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92687aed",
   "metadata": {
    "cellId": "bg0yiqx228i5r0stkx3g97"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from model.model import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc6ac171",
   "metadata": {
    "cellId": "nwlo8y3vfrov463qnmp9bp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "    \n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "         \n",
    "        # If loss worsened\n",
    "        if loss_t >= loss_tm1:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "                train_state['early_stopping_best_val'] = loss_t\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"Normalize tensor sizes\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): the output of the model\n",
    "            If a 3-dimensional tensor, reshapes to a matrix\n",
    "        y_true (torch.Tensor): the target predictions\n",
    "            If a matrix, reshapes to be a vector\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    \n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "    \n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a999063",
   "metadata": {
    "cellId": "t1fyxxao6uuo27ltqxg8b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import random \n",
    "\n",
    "def batch_generator(rus_data, rsl_data, batch_size=32):\n",
    "    rus_data = np.array(rus_data)\n",
    "    rsl_data = np.array(rsl_data)\n",
    "    \n",
    "    data_length = len(rus_data)\n",
    "    tail_length = batch_size - data_length % batch_size\n",
    "    index = list(range(data_length))\n",
    "    random.shuffle(index)\n",
    "    \n",
    "    index = np.array(index + random.choices(index, k=tail_length))\n",
    "    num_batches = len(index) // batch_size\n",
    "    index = index.reshape((num_batches, batch_size))\n",
    "    \n",
    "    for batch_ind, inds in enumerate(tqdm(index)):\n",
    "        yield batch_ind, torch.tensor(rus_data[inds]), torch.tensor(rsl_data[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "559cef06",
   "metadata": {
    "cellId": "a7jeq5vt1udvdi11j9x5vn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(\n",
    "    seed = 1337,\n",
    "    learning_rate = 5e-4, \n",
    "    batch_size = 64,  # 64\n",
    "    num_epochs = 30,  # 30\n",
    "    rus_emb_size = 16,  # 16\n",
    "    rsl_emb_size = 16,  # 16\n",
    "    rnn_size = 64,  # 64\n",
    "    early_stopping_criteria = 5,\n",
    "    mask_index = voc_rsl.mask_ind,\n",
    "    max_norm = 2.0,\n",
    "    norm_type = 2\n",
    ")\n",
    "\n",
    "set_seed_everywhere(args.seed, torch.cuda.is_available())\n",
    "\n",
    "model_zero = Translator(voc_rus.word_count, args.rus_emb_size, voc_rsl.word_count, args.rsl_emb_size, args.rnn_size, voc_rsl.bos_ind)\n",
    "\n",
    "optimizer = optim.Adam(model_zero.parameters(), lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b7aca8b",
   "metadata": {
    "cellId": "y3oikfk28p8xjpoto8jze9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1603e0cd",
   "metadata": {
    "cellId": "0wul38qeocbp3fhfnui9hvv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(14666, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(14916, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=14916, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model_zero.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56452d45",
   "metadata": {
    "cellId": "8p1ulyaaiateanh5tvkmi9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 887/887 [01:40<00:00,  8.86it/s]\n",
      "100%|██████████| 887/887 [01:40<00:00,  8.78it/s]\n",
      "100%|██████████| 887/887 [01:42<00:00,  8.63it/s]\n",
      "100%|██████████| 887/887 [01:44<00:00,  8.52it/s]\n",
      "100%|██████████| 887/887 [01:45<00:00,  8.43it/s]\n",
      "100%|██████████| 887/887 [01:45<00:00,  8.40it/s]\n",
      "100%|██████████| 887/887 [01:47<00:00,  8.27it/s]\n",
      "100%|██████████| 887/887 [01:48<00:00,  8.19it/s]\n",
      "100%|██████████| 887/887 [01:48<00:00,  8.15it/s]\n",
      "100%|██████████| 887/887 [01:50<00:00,  8.05it/s]\n",
      "100%|██████████| 887/887 [01:51<00:00,  7.95it/s]\n",
      "100%|██████████| 887/887 [01:52<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Loss:  5.767959586394009 \tacc:  43.59903381642512 \tsample_prob:  0.05\n",
      "Epoch:  1 Loss:  2.864862790236745 \tacc:  86.68866886688669 \tsample_prob:  0.05\n",
      "Epoch:  2 Loss:  1.4609341984940207 \tacc:  84.42796610169492 \tsample_prob:  0.05\n",
      "Epoch:  3 Loss:  0.9825745606637453 \tacc:  93.34126040428062 \tsample_prob:  0.05\n",
      "Epoch:  4 Loss:  0.8086890170377978 \tacc:  89.05882352941177 \tsample_prob:  0.05\n",
      "Epoch:  5 Loss:  0.7060141920573011 \tacc:  85.18134715025907 \tsample_prob:  0.05\n",
      "Epoch:  6 Loss:  0.6171984850537149 \tacc:  94.7560975609756 \tsample_prob:  0.05\n",
      "Epoch:  7 Loss:  0.5721194001067991 \tacc:  91.46211312700106 \tsample_prob:  0.05\n",
      "Epoch:  8 Loss:  0.5269220709767122 \tacc:  95.24348810872027 \tsample_prob:  0.05\n",
      "Epoch:  9 Loss:  0.5216604913285644 \tacc:  86.41370869033048 \tsample_prob:  0.05\n",
      "Epoch:  10 Loss:  0.47905228491515595 \tacc:  98.28269484808455 \tsample_prob:  0.05\n",
      "Epoch:  11 Loss:  0.4368459423867461 \tacc:  88.82618510158014 \tsample_prob:  0.05\n",
      "Epoch:  12 Loss:  0.4391387876799367 \tacc:  92.50513347022587 \tsample_prob:  0.05\n",
      "Epoch:  13 Loss:  0.42845443258610083 \tacc:  92.46954595791806 \tsample_prob:  0.05\n",
      "Epoch:  14 Loss:  0.4201330345884184 \tacc:  100.0 \tsample_prob:  0.05\n",
      "Epoch:  15 Loss:  0.5056178527374956 \tacc:  92.7536231884058 \tsample_prob:  0.06666666666666667\n",
      "Epoch:  16 Loss:  1.025602981536371 \tacc:  81.34414831981461 \tsample_prob:  0.13333333333333333\n",
      "Epoch:  17 Loss:  1.448371119856028 \tacc:  71.70900692840647 \tsample_prob:  0.2\n",
      "Epoch:  18 Loss:  1.889541495562003 \tacc:  67.4812030075188 \tsample_prob:  0.26666666666666666\n",
      "Epoch:  19 Loss:  2.347687606679818 \tacc:  80.04613610149943 \tsample_prob:  0.3333333333333333\n",
      "Epoch:  20 Loss:  2.7217712562275027 \tacc:  55.71095571095571 \tsample_prob:  0.4\n",
      "Epoch:  21 Loss:  3.071391755725513 \tacc:  51.737451737451735 \tsample_prob:  0.4666666666666667\n",
      "Epoch:  22 Loss:  3.502512981281474 \tacc:  55.04994450610433 \tsample_prob:  0.5333333333333333\n",
      "Epoch:  23 Loss:  3.8331287329199575 \tacc:  43.06326304106548 \tsample_prob:  0.6\n",
      "Epoch:  24 Loss:  4.192056359406115 \tacc:  44.06976744186046 \tsample_prob:  0.6666666666666666\n",
      "Epoch:  25 Loss:  4.35823267153985 \tacc:  41.00801832760595 \tsample_prob:  0.7333333333333333\n",
      "Epoch:  26 Loss:  4.4216808369624765 \tacc:  35.278514588859416 \tsample_prob:  0.8\n",
      "Epoch:  27 Loss:  4.330864848789525 \tacc:  40.770101925254814 \tsample_prob:  0.8666666666666667\n",
      "Epoch:  28 Loss:  4.1661630254721835 \tacc:  37.826086956521735 \tsample_prob:  0.9333333333333333\n",
      "Epoch:  29 Loss:  3.937165508678824 \tacc:  42.02127659574468 \tsample_prob:  1.0\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# train\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    # sample_probability = (10 + epoch_index) / args.num_epochs\n",
    "    if epoch_index < 0.5 * args.num_epochs:\n",
    "        sample_probability = 0.05\n",
    "    else:\n",
    "        sample_probability = ( 2 * (epoch_index+1) - args.num_epochs) / args.num_epochs\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    model_zero.train()\n",
    "    \n",
    "    for batch_ind, rus_batch, rsl_batch in batch_generator(vec_sentences_rus_train, vec_sentences_rsl_train, args.batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        rus_batch = rus_batch.to(device)\n",
    "        rsl_batch = rsl_batch.to(device)\n",
    "        \n",
    "        y_pred = model_zero(rus_batch, rsl_batch, sample_probability)  # 0.0\n",
    "        y_pred = y_pred.to(device)\n",
    "        \n",
    "        loss = sequence_loss(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        #nn.utils.clip_grad_value_(model_zero.parameters(), clip_value=1.0)\n",
    "        nn.utils.clip_grad_norm_(model_zero.parameters(), args.max_norm, args.norm_type)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += (loss.item() - running_loss) / (batch_ind + 1)\n",
    "        acc_t = compute_accuracy(y_pred, rsl_batch, args.mask_index)\n",
    "        \n",
    "    print('Epoch: ', epoch_index, 'Loss: ', running_loss, '\\tacc: ', acc_t, '\\tsample_prob: ', sample_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe5c4a83",
   "metadata": {
    "cellId": "tugce1dr2qg24zyuj44god"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "torch.save(model_zero.state_dict(), \"model30_gen_clean.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0021a131",
   "metadata": {
    "cellId": "evtwzygzksa8gej5xnz5ie"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model_zero = Translator(voc_rus.word_count, args.rus_emb_size,\n",
    "                        voc_rsl.word_count, args.rsl_emb_size,\n",
    "                        args.rnn_size, voc_rsl.bos_ind)\n",
    "model_zero.load_state_dict(torch.load(\"model30_gen_clean.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6912fbb2",
   "metadata": {
    "cellId": "1j28d9kvyilpjj0a664e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translator(\n",
       "  (encoder): TranslatorEncoder(\n",
       "    (rus_embeddings): Embedding(14666, 16, max_norm=1.0)\n",
       "    (rus_birnn): GRU(16, 64, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): TranslatorDecoder(\n",
       "    (rsl_embedding): Embedding(14916, 16, max_norm=1.0)\n",
       "    (gru_cell): GRUCell(144, 128)\n",
       "    (linear_map): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (classifier): Linear(in_features=256, out_features=14916, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model_zero.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b8e65a",
   "metadata": {
    "cellId": "ep9ebcjpvwcqt3a6rupuel"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "regex = re.compile(r'(?:<bos>|<eos>.*)')\n",
    "def pred_vs_rsl(tensor, true_rsl, rus): \n",
    "    \n",
    "    tensor = tensor.argmax(2).tolist()\n",
    "    \n",
    "    pred_rsl = voc_rsl.index_to_text(tensor)\n",
    "    true_rsl = voc_rsl.index_to_text(true_rsl)\n",
    "    rus = voc_rus.index_to_text(rus)\n",
    "                   \n",
    "    f = lambda x: regex.sub('', \" \".join(x))\n",
    "                   \n",
    "    pred_rsl = [f(sentence) for sentence in pred_rsl]\n",
    "    true_rsl = [f(sentence) for sentence in true_rsl]\n",
    "    true_rus = [f(sentence) for sentence in rus]\n",
    "    \n",
    "    return pred_rsl, true_rsl, true_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f70268c0",
   "metadata": {
    "cellId": "cxc5douk3bt18uk6ckipsd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "vec_sentences_rus_test = voc_rus.text_to_index(list(test_data['test_stem_rus']))\n",
    "vec_gram_test = bin_gram.transform(list(test_data['test_gram_rus']))\n",
    "vec_sentences_rsl_test = voc_rsl.text_to_index(list(test_data['test_rsl']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efd30ac",
   "metadata": {
    "cellId": "q3otc4h64bb4k6q1d5hnc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "rus = torch.tensor(vec_sentences_rus_test).to(device)\n",
    "rsl = torch.tensor(vec_sentences_rsl_test).to(device)\n",
    "y_pred = model_zero(rus,\n",
    "                    rsl, 1)  #0\n",
    "trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
    "                                    rsl,\n",
    "                                    rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5973dc7",
   "metadata": {
    "cellId": "cx1n6zri1zp1na7kms4tv7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14666, 14916)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "voc_rus.word_count, voc_rsl.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c88c58a8",
   "metadata": {
    "cellId": "qfwekt5rdne0u1tus2bm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSL:   indx дед.мороз clf <unk> clf.переместить домой clf <unk> clf.переместить дед.мороз маленький <unk> приходить обращение главный 1ps был лес подарок clf <unk> \n",
      "TRANS:   все чуть-чуть дед мороз вернуться преподаватель преподаватель дед мороз приходить 1ps 1ps 1ps 1ps 1ps 3ps 3ps \n",
      "RUS:   а когда дед мороз вернуться домой маленький дед мороз приходить к главный и сказать а я то вон в лес тоже подарок раздавать \n",
      "\n",
      "\n",
      "RSL:   мама второй 3ps все радость давать 1ps ноль \n",
      "TRANS:   2ps 1ps утопать \n",
      "RUS:   а мачеха лишать я весь радость \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   вообще раньше 1ps был indx быть год год год год 1ps у 2ps 1ps indx форум форум форум 1ps indx 1ps indx indx <dact> <dact> indx 1ps 1ps <dact> 1ps 1ps <dact> 1ps 1ps \n",
      "RUS:   вообще я думать что мочь быть в следующий год у мы тоже быть план проводить форум и это форум будет включать в себя в то число и вопрос об опыт <unk> в другой регион \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   четвертый мама мама 3ps свой дело по \n",
      "RUS:   проходить <unk> мама проводить <unk> свой хвост по спина <unk> чтобы <unk> \n",
      "\n",
      "\n",
      "RSL:   зачем желание изменение все4 привычка тратить все4 желание <unk> привычка свой изменение тратить и копить думать \n",
      "TRANS:   еще 1ps 1ps кивать свой \n",
      "RUS:   зачем я хотеть изменять свой привычка тратить и начинать копить \n",
      "\n",
      "\n",
      "RSL:   <unk> есть poss 3ps 3ps рассказ 1ps интересный <unk> первый прогресс \n",
      "TRANS:   самец лодка это другой \n",
      "RUS:   оказываться впервые это появляться в <unk> \n",
      "\n",
      "\n",
      "RSL:   1ps вчера стирать <dact> не был \n",
      "TRANS:   1ps вчера \n",
      "RUS:   я вчера не стирать белье \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   3ps кот что \n",
      "RUS:   это мелочь который мочь <unk> вы в работа \n",
      "\n",
      "\n",
      "RSL:    \n",
      "TRANS:   у он он быть русский \n",
      "RUS:   у он должно быть обсуждение с вы который обычно нет \n",
      "\n",
      "\n",
      "RSL:   обувь2 убирать чулок бродить дверь 1ps думать радость 3ps скоро открывать.дверь сейчас скоро радость <unk> \n",
      "TRANS:   близнец один один животное трава2 1ps 1ps вместе2 и <dact> 3ps 3ps 3ps 3ps 3ps 1ps 1ps 1ps \n",
      "RUS:   она один за другой <unk> с себя туфля и прямо в один чулок подходить к дверь и у я от радость <unk> сердце \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for i in range(10):\n",
    "    print(\"RSL: \", truth_rsl[i])\n",
    "    print(\"TRANS: \", trans[i])\n",
    "    print(\"RUS: \", rus[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e46389",
   "metadata": {
    "cellId": "o9ddm7y93spbv1bdaxfr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Russian to RSL:  2.8074663382150127\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import sacrebleu\n",
    "\n",
    "rus_rsl_bleu = sacrebleu.corpus_bleu(trans, [truth_rsl])\n",
    "print(\"--------------------------\")\n",
    "print(\"Russian to RSL: \", rus_rsl_bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ceb8cdc",
   "metadata": {
    "cellId": "unacgvfwpiphyzapp3z37t"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# save results to file\n",
    "result_data = pd.DataFrame.from_dict({\"truth RSL\": truth_rsl, \"TRANS\": trans, \"RUS\": rus})\n",
    "result_data.to_csv('test_result.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffca5c",
   "metadata": {
    "cellId": "pms1ev8ugjsc1zs8h7szj7"
   },
   "source": [
    "### Tests with separate sentences... (Подвал)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "02425797",
   "metadata": {
    "cellId": "0hpnnmuo1ftddo75s89zd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "[np.array([0] * 81)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3eaf4a17",
   "metadata": {
    "cellId": "ycqrgt7qrej0pi6wv8cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([    2,   351, 10499,  1039,   630,   146,   144,     3,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "[vec_sentences_rus_test[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3db6bde",
   "metadata": {
    "cellId": "jnqxiq0r28r4tbxd7n0g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "y_pred = model_zero(torch.tensor([vec_sentences_rus_test[1]]), torch.tensor([np.array([1] * 81)]), 0)  #torch.tensor(vec_sentences_rsl_test), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "190aa1a6",
   "metadata": {
    "cellId": "xxzlsjfqklnp5h2aqb4htm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
    "                                    torch.tensor([vec_sentences_rsl_test[1]]),\n",
    "                                    torch.tensor([vec_sentences_rus_test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a83dcec1",
   "metadata": {
    "cellId": "h8vghpqpii49vghh5ojydl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSL:   мама второй 3ps все радость давать 1ps ноль \n",
      "TRANS:   велосипедист хулиган велосипедист на жопник плато плато стеклянный сам2 на внутри.себя на газированный на clf.стоят на всегда2 газированный внутри.себя на на внутри.себя внутри.себя внутри.себя clf.опуститься clf.опуститься внутри.себя внутри.себя внутри.себя внутри.себя внутри.себя газированный газированный газированный внутри.себя clf.опуститься газированный clf.опуститься clf.опуститься газированный внутри.себя clf.опуститься внутри.себя газированный clf.опуститься внутри.себя газированный clf.опуститься clf.опуститься газированный clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься газированный газированный clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься clf.опуститься\n",
      "RUS:   а мачеха лишать я весь радость \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6ea150407625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lets have a look\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RSL: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth_rsl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRANS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RUS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# lets have a look\n",
    "for i in range(10):\n",
    "    print(\"RSL: \", truth_rsl[i])\n",
    "    print(\"TRANS: \", trans[i])\n",
    "    print(\"RUS: \", rus[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f814b59",
   "metadata": {
    "cellId": "pxx3hb8mmbd8qe3ng13dpv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# одно предложение с хорошим переводом поменять пару слов местами\n",
    "vec_sentences_rus_more = voc_rus.text_to_index([['а', 'отец', 'лишать', 'я', 'весь', 'радость']])\n",
    "vec_sentences_rsl_more = voc_rsl.text_to_index([['мама', 'второй', '3ps', 'все', 'радость', 'давать', '1ps', 'ноль']])\n",
    "y_pred = model_zero(torch.tensor(vec_sentences_rus_more), torch.tensor(vec_sentences_rsl_more), 1)  #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d661aecb",
   "metadata": {
    "cellId": "gre32yz2knpj0k7lctdmlk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
    "                                    torch.tensor(vec_sentences_rsl_more),\n",
    "                                    torch.tensor(vec_sentences_rus_more))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f14e7016",
   "metadata": {
    "cellId": "r5bvwj7tx18mwro7j2tu8k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSL:  [' мама второй 3ps все радость давать 1ps ноль ']\n",
      "TRANS:  [' мама второй 3ps все радость давать 1ps ноль ']\n",
      "RUS:  [' а отец лишать я весь радость ']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(\"RSL: \", truth_rsl)\n",
    "print(\"TRANS: \", trans)\n",
    "print(\"RUS: \", rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02a72a66",
   "metadata": {
    "cellId": "j205sq3qcgh7zq414cdq6n"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "select(): index 14678 out of range for tensor of size [14666, 16] at dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ccc8c39c7b99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_sentences_rsl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_sentences_rsl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_sentences_rsl_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     torch.tensor(vec_sentences_rus_test))\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rus_sentances, rsl_sentence, sample_probability)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus_sentances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsl_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mencoder_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrus_sentances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mdecoded_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsl_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rus_sentances)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrus_sentances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrus_birnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrus_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrus_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrus_sentances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# rus_rnn_h.shape = (rnn_size, batch_size, rus_emb_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;31m#   torch.embedding_renorm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_no_grad_embedding_renorm_\u001b[0;34m(weight, input, max_norm, norm_type)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1946\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: select(): index 14678 out of range for tensor of size [14666, 16] at dimension 0"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred = model_zero(torch.tensor(vec_sentences_rsl_test), torch.tensor(vec_sentences_rsl_test), 1)  #0\n",
    "trans, truth_rsl, rus = pred_vs_rsl(y_pred,\n",
    "                                    torch.tensor(vec_sentences_rsl_test),\n",
    "                                    torch.tensor(vec_sentences_rus_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "69016dcc-b649-4bac-9ee6-cf069903adc3",
  "notebookPath": "Notebooks/clean_generation.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
